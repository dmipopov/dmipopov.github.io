[{"content":"It\u0026rsquo;s not difficult to deploy an application in Kubernetes with minimal working configuration. But when you want to provide your application with maximum availability and reliability, you will inevitably encounter a considerable number of pitfalls. In this article, I tried to systematize and describe the most important rules for deploying highly available applications in Kubernetes.\nFunctionality that is not available in Kubernetes \u0026ldquo;out of the box\u0026rdquo; will hardly be affected here. Also, I won\u0026rsquo;t be tied to specific CD solutions and will omit the issues of templating/generating Kubernetes manifests.\n1. Number of replicas # It\u0026rsquo;s hard to talk about any availability if the application doesn\u0026rsquo;t work in at least 2 replicas. Why are there problems when launching an application in 1 replica? Many Kubernetes objects (Node, Pod, ReplicaSet, etc.) can be automatically deleted/recreated under certain conditions, so Kubernetes cluster and the applications running in it should be ready for such situations.\nFor example, when autoscaling nodes down, some nodes along with the Pods running on them will be deleted. If your application is running in a single instance on the node being deleted at this time, application will be unavaileble for some time. In general, when working in the same replica, any abnormal shutdown of the application will mean a downtime. Thus, the application must be running in at least 2 replicas.\nThe recommendations are relevant if HorizontalPodAutoscaler is not used. The best option for applications that will have more than a few replicas is to configure HorizontalPodAutoscaler and forget about specifying the number of replicas manually.\n2. Uniform distribution of replicas by nodes # It\u0026rsquo;s very important to distribute application Pods to different nodes if the application is running in multiple replicas. To do this, recommend the scheduler not to run multiple Pods of the same Deployment on the same node:\naffinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: labelSelector: matchLabels: app: testapp topologyKey: kubernetes.io/hostname Use preferredDuringScheduling instead of requiredDuringScheduling, which may make it impossible to launch new Pods if there are fewer available nodes than the new Pods require. However, requiredDuringScheduling can be useful when the number of nodes and replicas of the application is precisely known and you need to be sure that two Pods won\u0026rsquo;t be run on the same node.\n3. PriorityClass # priorityClassName affects which Pods will be scheduled in the first place, as well as which Pods can be evicted by the scheduler if there\u0026rsquo;s no space left for new Pods on the nodes.\nYou\u0026rsquo;ll need to create several resources of the PriorityClass type and associate them with the Pods via priorityClassName. A set of PriorityClass may look something like this:\nName Value Description Cluster 20000 Critical components for functioning of the cluster, such as kube-api server Daemonsets 10000 Usually we want DaemonSet\u0026rsquo;s Pods not to be evicted by regular applications Production-high 9000 Stateful apps Production-medium 8000 Stateless apps Default 7000 Non-production apps 4. Update strategy # TODO\n5. Stopping processes in containers # TODO\n6. Probes # TODO\n6.1 Liveness probe # TODO\n6.2 Readiness probe # TODO\n6.3 Startup probe # TODO\n","date":"17 July 2022","permalink":"/posts/best-practices-for-deploying-high-available-applications-in-kubernetes/","section":"Posts","summary":"It\u0026rsquo;s not difficult to deploy an application in Kubernetes with minimal working configuration.","title":"Best Practices for Deploying High Available Applications in Kubernetes"},{"content":" Cybersecurity student at HSE and DevOps engineer. Hi, I am a 5th year cybersecurity student at HSE and DevOps engineer. This blog is for fun, do not take it too seriously.\n","date":"17 July 2022","permalink":"/","section":"Dmitry Popov","summary":"Cybersecurity student at HSE and DevOps engineer.","title":"Dmitry Popov"},{"content":"","date":"17 July 2022","permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes"},{"content":"","date":"17 July 2022","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"17 July 2022","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"31 March 2022","permalink":"/tags/helm/","section":"Tags","summary":"","title":"Helm"},{"content":"Methods of secrets delivery # Secrets need to be somehow delivered to Kubernetes clusters. There are two different approaches for this: pull and push.\nPull # Secrets are delivered to clusters after deployment. For instance, if we use Helm Charts, we can specify metadata instead of the secret value.\nWe do not add secret values to the manifests at all, but specify only metadata. Secrets are created based on this metadata and downloaded from external storage \u0026ndash; for example, Hashicorp Vault.\nPush # Secrets are delivered to clusters immediately during deployment. We specify secrets in the manifests when creating resources with secrets in the process of deployment.\nThe easiest way to store secrets safely in repository \u0026ndash; encrypt them in manifests or in Helm Charts. And we decrypt them only when we apply our manifests. Or after apply, if we use an intermediate k8s resource.\nThe example below describes push method with Helm plugin helm-secrets, sops and vals. This combination of tools allow us to safely store secrets in git repository and easily deploy Helm Charts with decrypted secrets without Hashicorp Vault installation and maintenance.\nSops # Sops allows us to encrypt YAML/JSON files with AWS KMS, GCP KMS, Azure Key Vault and PGP.\nIn this example we will be using PGP key. Let\u0026rsquo;s generate it:\n$ gpg --gen-key Fill in your full name and email and you\u0026rsquo;ll see:\n... public and secret key created and signed. pub ed25519 2022-03-30 [SC] [expires: 2024-03-29] 770281CBDD9AD22235A1790DC10C6C36DA3C6597 uid Dmitry Popov \u0026lt;dmipopov01@gmail.com\u0026gt; sub cv25519 2022-03-30 [E] [expires: 2024-03-29] You can list all your keys with gpg --list-keys\n... /home/dima/.gnupg/pubring.kbx ----------------------------- pub ed25519 2022-03-30 [SC] [expires: 2024-03-29] 770281CBDD9AD22235A1790DC10C6C36DA3C6597 uid [ultimate] Dmitry Popov \u0026lt;dmipopov01@gmail.com\u0026gt; sub cv25519 2022-03-30 [E] [expires: 2024-03-29] pub ed25519 2022-03-30 [SC] [expires: 2024-03-29] 907DA4CB86ECFCCE67CF01FF1D5C44EF6E555F1A uid [ultimate] Dmitry Popov \u0026lt;dmipopov01@sberbank.ru\u0026gt; sub cv25519 2022-03-30 [E] [expires: 2024-03-29] I have 2 keys on my host and we can use different keys for dev- and prod-environment.\nLet\u0026rsquo;s create secrets that we want to encrypt:\nsecrets.dev.yaml\ndev: redis_password: \u0026#34;amazing_redis_password\u0026#34; app_api_key: \u0026#34;1a2b3c4d\u0026#34; secrets.prod.yaml\nprod: redis_password: \u0026#34;shhhhh_redis_password\u0026#34; app_api_key: \u0026#34;12312312312121231312313\u0026#34; Now let\u0026rsquo;s create .sops.yaml to specify file masks and PGP keys for them:\ncreation_rules: - path_regex: \\.*dev*\\.yaml$ pgp: 770281CBDD9AD22235A1790DC10C6C36DA3C6597 - path_regex: \\.*prod*\\.yaml$ pgp: 907DA4CB86ECFCCE67CF01FF1D5C44EF6E555F1A Let\u0026rsquo;s encypt our dev secrets:\n$ sops -e secrets.dev.yaml \u0026gt; enc.secrets.dev.yaml $ cat enc.secrets.dev.yaml dev: redis_password: ENC[AES256_GCM,data:CsIjY1m02nXRbEmwbRuRlOjA3XAH0A==,iv:KIDiAkJHk/iOfaQmQFneIae3bMM21nwHM+3XQueq0/I=,tag:FGSDIO45xV4F+i6etL03sA==,type:str] app_api_key: ENC[AES256_GCM,data:JZguc/TXYKM=,iv:so3U6MQekqaz4HKZ9c/+Q8VAFRUbqr8mXwE+kp5gdt0=,tag:D69EWGAKkOxg6Brm6zIJqw==,type:str] sops: kms: [] gcp_kms: [] azure_kv: [] hc_vault: [] age: [] lastmodified: \u0026#34;2022-03-30T20:39:21Z\u0026#34; mac: ENC[AES256_GCM,data:Yqmx+PagcpPH7VM5pbq+9Z3c5bhhtMb1vkIgoHn9TLHeJylT7vRrXLYCjVzR9jNFaWtPo8voToF9xbBXfAtHBkW2xgAe3tG/ckOFSf0+SH2I3ReCKbdUOn5TTiIFZJhSZSYruCgjPwvHH6Ghd0qA8tVMKKF8eir50h7G8/mGnSs=,iv:lltyB5VyzgHkmlgobqh/Fi7NlqjV9wLICrm9qQLY/84=,tag:Kbyy37K9kN9+8Fpyk7eGzw==,type:str] pgp: - created_at: \u0026#34;2022-03-30T20:39:00Z\u0026#34; enc: | -----BEGIN PGP MESSAGE----- hF4DFRPRFvydS5gSAQdAXkkCfQJ4+GcAl4r8v/6GaIYXbqK34nsWzGbK9bCwsQUw z4ibV8tO2OGjRDxgRlEwCaua33pqO98uhz8UYb2q6UQOGjMWNf7yk6e4ZnNXR5n0 1GgBCQIQGvPhXe71G8As/VY11fxtAynLrQyVC+M6zveyfA7HU9RuBQBJir6frmY8 6v0k3wjVWR9YfezCr/dl9QreAy/vYgmgbDI3+D0zxIrw/h55WKGVlgRYSrAetg+f Rs5tFC/Ugdhxrg== =BG+c -----END PGP MESSAGE----- fp: 770281CBDD9AD22235A1790DC10C6C36DA3C6597 unencrypted_suffix: _unencrypted version: 3.7.2 As we can see sops saved the structure of secrets.dev.yaml and now our secrets are encrpyted.\nCommand sops -d enc.secrets.dev.yaml will decrypt and print our secrets.\nFor in-place editing use sops -i. You have to carry keys, but it\u0026rsquo;s easy to import them:\n$ gpg --armor --export-secret-key 770281CBDD9AD22235A1790DC10C6C36DA3C6597 \u0026gt; key-prod.gpg $ gpg --allow-secret-key-import --import key-prod.gpg Helm-secrets + sops # Helm-secrets \u0026ndash; is Helm plugin that can be used with sops when we want to deploy Helm Chart.\nInstallation:\n$ helm plugin install https://github.com/jkroepke/helm-secrets --version v3.12.0 Some helm-secrets features:\nPrint out secrets with helm secrets view secrets.dev.yaml In-place encryption with helm secrets enc secrets.dev.yaml Editing with helm secrets edit secrets.dev.yaml by $EDITOR Automatic rendering of secret values while deploying: $ helm secrets upgrade --install some-app -f values.yaml -f secrets.dev.yaml The biggest disadvantage of helm-secrets \u0026ndash; you can\u0026rsquo;t use several drivers at the same time.\nHelm-secrets + sops + vals # Vals \u0026ndash; tool that allows us to refer to different sources of secrets: sops, vault, aws, gcp.\nWe\u0026rsquo;ll be using vals as driver for helm-secret.\nUsing vals is pretty easy \u0026ndash; just store link to secret value directly in values.yaml:\ndev: secret1: ref+sops://path/to/file#/foo/bar secret2: ref+vault://mykv/foo#/bar?address=https://vault1.example.com:8200 secret3: ref+gcs://BUCKET/KEY/OF/OBJECT[?generation=ID] The killer feature of vals is that we can place secrets from different sources in 1 file.\nWe can simply view our secrets from values.yaml by vals:\n$ helm secrets -d vals view values.yaml - Render our secrets file:\n$ helm secrets -d vals -f values.yaml template . And deploy with decrypted secrets:\n$ helm secrets -d vals upgrade --install some-app -f values.yaml The combination of helm-secrets, sops and vals simplifies management of secrets. It gives the ability to store them safely in git, the only thing to do is to manage GPG keys. And in the future it will be easier for you to migrate from sops to secrets storage such as Hashicorp Vault or AWS Secrets Manager.\n","date":"31 March 2022","permalink":"/posts/hide_kubernetes_secrets_with_helm_secrets_sops_and_vals/","section":"Posts","summary":"Methods of secrets delivery # Secrets need to be somehow delivered to Kubernetes clusters.","title":"Hide Kubernetes secrets with helm-secrets, sops and vals"}]